{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f04e5d4-7410-47d5-b92e-b22de0727688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Using cached torch-2.7.1-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.22.1-cp312-cp312-win_amd64.whl.metadata (6.1 kB)\n",
      "Collecting torchaudio\n",
      "  Using cached torchaudio-2.7.1-cp312-cp312-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\nader\\anaconda3\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\nader\\anaconda3\\lib\\site-packages (from torch) (4.11.0)\n",
      "Collecting sympy>=1.13.3 (from torch)\n",
      "  Using cached sympy-1.14.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: networkx in c:\\users\\nader\\anaconda3\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\nader\\anaconda3\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\nader\\anaconda3\\lib\\site-packages (from torch) (2024.3.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nader\\anaconda3\\lib\\site-packages (from torch) (69.5.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\nader\\anaconda3\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\nader\\anaconda3\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\nader\\anaconda3\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nader\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Using cached torch-2.7.1-cp312-cp312-win_amd64.whl (216.1 MB)\n",
      "Using cached torchvision-0.22.1-cp312-cp312-win_amd64.whl (1.7 MB)\n",
      "Using cached torchaudio-2.7.1-cp312-cp312-win_amd64.whl (2.5 MB)\n",
      "Using cached sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "Installing collected packages: sympy, torch, torchvision, torchaudio\n",
      "Successfully installed sympy-1.14.0 torch-2.7.1 torchaudio-2.7.1 torchvision-0.22.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\nader\\anaconda3\\Lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution ~ympy (C:\\Users\\nader\\anaconda3\\Lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fdb36a2a-d277-4827-861c-e7549bbeae56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTING LIBRARIES ---------------------------------------------\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "#DEFINING FEATURES - RGB, Resize, Normalize ------------------------\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], \n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    )\n",
    "])\n",
    "\n",
    "#LOAD DATASET -------------------------------------------------------\n",
    "\n",
    "train_data = ImageFolder(root='data/train', transform=transform)\n",
    "test_data = ImageFolder(root='data/test', transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "961737de-b121-423a-9390-3f6d7b71797f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nader\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\nader\\anaconda3\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\nader/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 44.7M/44.7M [02:14<00:00, 348kB/s]\n"
     ]
    }
   ],
   "source": [
    "resnet = models.resnet18(pretrained=True)\n",
    "resnet.eval()\n",
    "\n",
    "# Remove the final classification layer\n",
    "feature_extractor = torch.nn.Sequential(*list(resnet.children())[:-1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "96a860cf-3843-45ee-8596-e567f5a228e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(dataloader):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in tqdm(dataloader):\n",
    "            outputs = feature_extractor(inputs)\n",
    "            outputs = outputs.view(outputs.size(0), -1)  # Flatten\n",
    "            features.append(outputs)\n",
    "            labels.append(targets)\n",
    "\n",
    "    X = torch.cat(features).numpy()\n",
    "    y = torch.cat(labels).numpy()\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8988e561-0746-4f04-8089-f2847e5070b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [01:16<00:00,  2.13s/it]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:16<00:00,  1.80s/it]\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = extract_features(train_loader)\n",
    "X_test, y_test = extract_features(test_loader)\n",
    "\n",
    "np.save('X_train.npy', X_train)\n",
    "np.save('y_train.npy', y_train)\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('y_test.npy', y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2b7d1cfa-3246-4993-9f65-6b284b2348f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nader\\project\\plant-classifier\n"
     ]
    }
   ],
   "source": [
    "cd C:\\Users\\nader\\project\\plant-classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de48cf4-6ff9-465b-a94d-455470c681a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
